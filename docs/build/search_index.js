var documenterSearchIndex = {"docs":
[{"location":"datasets/#Datasets","page":"Datasets","title":"Datasets","text":"","category":"section"},{"location":"datasets/#Phone-data","page":"Datasets","title":"Phone data","text":"","category":"section"},{"location":"datasets/","page":"Datasets","title":"Datasets","text":"LinRegOutliers.phones","category":"page"},{"location":"datasets/#LinRegOutliers.phones","page":"Datasets","title":"LinRegOutliers.phones","text":"Phone data\n\nComponents\n\nyear::Integer: years from 1950 to 1973.\ncalls::Float64: phone calls (in millions).\n\nReference\n\nP. J. Rousseeuw and A. M. Leroy (1987) Robust Regression &      Outlier Detection. Wiley.\n\n\n\n\n\n","category":"constant"},{"location":"datasets/#Hawkings-and-Bradu-and-Kass-data","page":"Datasets","title":"Hawkings & Bradu & Kass data","text":"","category":"section"},{"location":"datasets/","page":"Datasets","title":"Datasets","text":"LinRegOutliers.hbk","category":"page"},{"location":"datasets/#LinRegOutliers.hbk","page":"Datasets","title":"LinRegOutliers.hbk","text":"Hawkins & Bradu & Kass data\n\nComponents\n\nx1::Float64: first independent variable.\nx2::Float64: second independent variable.\nx3::Float64: third independent variable.\ny::Float64: dependent (response) variable.\n\nReference\n\nHawkins, D.M., Bradu, D., and Kass, G.V. (1984) Location of several outliers in multiple regression data using elemental sets. Technometrics 26, 197–208.\n\n\n\n\n\n","category":"constant"},{"location":"datasets/#Animals-data","page":"Datasets","title":"Animals data","text":"","category":"section"},{"location":"datasets/","page":"Datasets","title":"Datasets","text":"LinRegOutliers.animals","category":"page"},{"location":"datasets/#LinRegOutliers.animals","page":"Datasets","title":"LinRegOutliers.animals","text":"Animals data\n\nComponents\n\nnames::AbstractString: names of animals.\nbody::Float64: body weight in kg.\nbrain::Float64: brain weight in g.\n\nReferences\n\n Venables, W. N. and Ripley, B. D. (1999) _Modern Applied\n Statistics with S-PLUS._ Third Edition. Springer.\n\n P. J. Rousseeuw and A. M. Leroy (1987) _Robust Regression and\n Outlier Detection._ Wiley, p. 57.\n\n\n\n\n\n","category":"constant"},{"location":"datasets/#Weight-Loss-data","page":"Datasets","title":"Weight Loss data","text":"","category":"section"},{"location":"datasets/","page":"Datasets","title":"Datasets","text":"LinRegOutliers.weightloss","category":"page"},{"location":"datasets/#LinRegOutliers.weightloss","page":"Datasets","title":"LinRegOutliers.weightloss","text":"Weight loss data\n\nComponents\n\ndays::Integer: time in days since the start of the diet program.\nweight::Float64: weight in kg.\n\nReference\n\n Venables, W. N. and Ripley, B. D. (1999) _Modern Applied\n Statistics with S-PLUS._ Third Edition. Springer.\n\n\n\n\n\n","category":"constant"},{"location":"datasets/#Stack-Loss-data","page":"Datasets","title":"Stack Loss data","text":"","category":"section"},{"location":"datasets/","page":"Datasets","title":"Datasets","text":"LinRegOutliers.stackloss","category":"page"},{"location":"datasets/#LinRegOutliers.stackloss","page":"Datasets","title":"LinRegOutliers.stackloss","text":"Stack loss data\n\nComponents\n\nairflow::Float64: flow of cooling air (independent variable).\nwatertemp::Float64: cooling water inlet temperature (independent variable).\nacidcond::Float64: concentration of acid (independent variable).\nstackloss::Float64: stack loss (dependent variable).\n\nOutliers\n\nObservations 1, 3, 4, and 21 are outliers.\n\nReferences\n\nBecker, R. A., Chambers, J. M. and Wilks, A. R. (1988) _The New S Language_.  Wadsworth & Brooks/Cole.\n\nDodge, Y. (1996) The guinea pig of multiple regression. In: _Robust Statistics, Data Analysis, and Computer Intensive Methods;\nIn Honor of Peter Huber's 60th Birthday_, 1996, _Lecture Notes in Statistics_ *109*, Springer-Verlag, New York.\n\n\n\n\n\n","category":"constant"},{"location":"datasets/#Hadi-and-Simonoff-(1993)-random-data","page":"Datasets","title":"Hadi & Simonoff (1993) random data","text":"","category":"section"},{"location":"datasets/","page":"Datasets","title":"Datasets","text":"LinRegOutliers.hs93randomdata","category":"page"},{"location":"datasets/#LinRegOutliers.hs93randomdata","page":"Datasets","title":"LinRegOutliers.hs93randomdata","text":"Hadi & Simonoff (1993) Random data\n\nComponents\n\nx1::Float64: Random values.\nx2::Float64: Random values.\ny::Float64: Random values (independent variable).\n\nOutliers\n\nObservations 1, 2, and 3 are outliers.\n\nReferences\n\nHadi, Ali S., and Jeffrey S. Simonoff. \"Procedures for the identification of  multiple outliers in linear models.\" Journal of the American Statistical  Association 88.424 (1993): 1264-1272.\n\n\n\n\n\n","category":"constant"},{"location":"datasets/#Modified-Wood-Gravity-data","page":"Datasets","title":"Modified Wood Gravity data","text":"","category":"section"},{"location":"datasets/","page":"Datasets","title":"Datasets","text":"LinRegOutliers.woodgravity","category":"page"},{"location":"datasets/#LinRegOutliers.woodgravity","page":"Datasets","title":"LinRegOutliers.woodgravity","text":"Modified Wood Gravity Data\n\nComponents\n\nx1::Float64: Random values.\nx2::Float64: Random values.\nx3::Float64: Random values.\nx4::Float64: Random values.\nx5::Float64: Random values.\ny::Float64: Random values (independent variable).\n\nReferences\n\nP. J. Rousseeuw and A. M. Leroy (1987) Robust Regression and Outlier Detection. Wiley, p.243, table 8.\n\n\n\n\n\n","category":"constant"},{"location":"datasets/#Scottish-Hill-Races-data","page":"Datasets","title":"Scottish Hill Races data","text":"","category":"section"},{"location":"datasets/","page":"Datasets","title":"Datasets","text":"LinRegOutliers.hills","category":"page"},{"location":"datasets/#LinRegOutliers.hills","page":"Datasets","title":"LinRegOutliers.hills","text":"Scottish Hill Races Data\n\nComponents\n\ndist::Array{Float64, 1}: Distance in miles (Independent). \nclimb::Array{Float64, 1}: Heights in feet (Independent).\ntime::Array{Float64, 1}: Record times in hours (Dependent).\n\nModel\n\ntime ~ dist + climb\n\nReferences\n\nA.C. Atkinson (1986) Comment: Aspects of diagnostic regression analysis. Statistical Science 1, 397-402.\n\n\n\n\n\n","category":"constant"},{"location":"datasets/#Soft-Drink-Delivery-data","page":"Datasets","title":"Soft Drink Delivery data","text":"","category":"section"},{"location":"datasets/","page":"Datasets","title":"Datasets","text":"LinRegOutliers.softdrinkdelivery","category":"page"},{"location":"datasets/#LinRegOutliers.softdrinkdelivery","page":"Datasets","title":"LinRegOutliers.softdrinkdelivery","text":"Soft Drink Delivery Data\n\nComponents\n\ncases::Array{Float64, 1}: Independent variable. \ndistance::Array{Float64, 1}: Independent variable. \ntime::Array{Float64, 1}: Dependent variable. \n\nModel\n\ntime ~ distance + cases \n\nReference\n\nD. C. Montgomery and E. A. Peck (1992) Introduction to Regression Analysis. Wiley, New York. \n\n\n\n\n\n","category":"constant"},{"location":"types/#Types","page":"Types","title":"Types","text":"","category":"section"},{"location":"types/#RegressionSetting","page":"Types","title":"RegressionSetting","text":"","category":"section"},{"location":"types/","page":"Types","title":"Types","text":"LinRegOutliers.RegressionSetting","category":"page"},{"location":"types/#LinRegOutliers.RegressionSetting","page":"Types","title":"LinRegOutliers.RegressionSetting","text":"struct RegressionSetting\n    formula::FormulaTerm\n    data::DataFrame\nend\n\nImmutable data structure for a regression setting.\n\nArguments\n\nformula::FormulaTerm: A formula object describes the linear regression model.\ndata::DataFrame: DataFrame object holds the data\n\nNotes\n\nImplemented methods in this packages accepts linear models as RegressionSetting objects.\nThis objects holds the model formula and the data used in regression estimations.\n\nExamples\n\njulia> setting = RegressionSetting(@formula(calls ~ year), phones)\nRegressionSetting(calls ~ year, 24×2 DataFrame\n│ Row │ year  │ calls   │\n│     │ Int64 │ Float64 │\n├─────┼───────┼─────────┤\n│ 1   │ 50    │ 4.4     │\n│ 2   │ 51    │ 4.7     │\n│ 3   │ 52    │ 4.7     │\n│ 4   │ 53    │ 5.9     │\n│ 5   │ 54    │ 6.6     │\n│ 6   │ 55    │ 7.3     │\n│ 7   │ 56    │ 8.1     │\n│ 8   │ 57    │ 8.8     │\n│ 9   │ 58    │ 10.6    │\n│ 10  │ 59    │ 12.0    │\n⋮\n│ 14  │ 63    │ 21.2    │\n│ 15  │ 64    │ 119.0   │\n│ 16  │ 65    │ 124.0   │\n│ 17  │ 66    │ 142.0   │\n│ 18  │ 67    │ 159.0   │\n│ 19  │ 68    │ 182.0   │\n│ 20  │ 69    │ 212.0   │\n│ 21  │ 70    │ 43.0    │\n│ 22  │ 71    │ 24.0    │\n│ 23  │ 72    │ 27.0    │\n│ 24  │ 73    │ 29.0    │)\n\n\n\n\n\n","category":"type"},{"location":"types/#OLS","page":"Types","title":"OLS","text":"","category":"section"},{"location":"types/","page":"Types","title":"Types","text":"##@docs ##LinRegOutliers.OLS ##","category":"page"},{"location":"diagnostics/#Diagnostics","page":"Diagnostics","title":"Diagnostics","text":"","category":"section"},{"location":"diagnostics/#dffit","page":"Diagnostics","title":"dffit","text":"","category":"section"},{"location":"diagnostics/","page":"Diagnostics","title":"Diagnostics","text":"LinRegOutliers.dffit","category":"page"},{"location":"diagnostics/#LinRegOutliers.dffit","page":"Diagnostics","title":"LinRegOutliers.dffit","text":"dffit(setting, i)\n\nCalculate the effect of the ith observation on the linear regression fit.\n\nArguments\n\nsetting::RegressionSetting: A regression setting object.\ni::Int: Index of the observation.\n\nExamples\n\njulia> reg = createRegressionSetting(@formula(calls ~ year), phones);\njulia> dffit(reg, 1)\n2.3008326745719785\n\njulia> dffit(reg, 15)\n2.7880619386124295\n\njulia> dffit(reg, 16)\n3.1116532421969794\n\njulia> dffit(reg, 17)\n4.367981450347031\n\njulia> dffit(reg, 21)\n-5.81610150322166\n\nReferences\n\nBelsley, David A., Edwin Kuh, and Roy E. Welsch. Regression diagnostics:  Identifying influential data and sources of collinearity. Vol. 571. John Wiley & Sons, 2005.\n\n\n\n\n\ndffit(setting)\n\nCalculate dffit for all observations.\n\nArguments\n\nsetting::RegressionSetting: A regression setting object.\n\nExamples\n\njulia> reg = createRegressionSetting(@formula(calls ~ year), phones);\n\njulia> dffit(reg)\n24-element Array{Float64,1}:\n   2.3008326745719785\n   1.2189579001467337\n   0.35535667547543426\n  -0.14458523141740898\n  -0.5558346324846752\n  -0.8441316814464983\n  -1.0329184407957257\n  -1.16600692151232\n  -1.2005633711667656\n  -1.2549187193476428\n  -1.3195581500053777\n  -1.42383876236147\n  -1.5917690629803474\n  -1.6582086833534504\n   2.7880619386124295\n   3.1116532421969794\n   4.367981450347031\n   5.927603041427858\n   8.442860517217582\n  12.370243663029527\n  -5.81610150322166\n -10.089153963127842\n -12.10803256546825\n -14.67006851119936\n\nReferences\n\nBelsley, David A., Edwin Kuh, and Roy E. Welsch. Regression diagnostics:  Identifying influential data and sources of collinearity. Vol. 571. John Wiley & Sons, 2005.\n\n\n\n\n\n","category":"function"},{"location":"diagnostics/#hatmatix","page":"Diagnostics","title":"hatmatix","text":"","category":"section"},{"location":"diagnostics/","page":"Diagnostics","title":"Diagnostics","text":"LinRegOutliers.hatmatrix","category":"page"},{"location":"diagnostics/#LinRegOutliers.hatmatrix","page":"Diagnostics","title":"LinRegOutliers.hatmatrix","text":"hatmatrix(setting)\n\nCalculate Hat matrix of dimensions n x n for a given regression setting with n observations.\n\nArguments\n\nsetting::RegressionSetting: A regression setting object.\n\nExamples\n\n```julia-repl julia> reg = createRegressionSetting(@formula(calls ~ year), phones); julia> size(hatmatrix(reg))\n\n(24, 24)\n\n\n\n\n\n","category":"function"},{"location":"diagnostics/#studentizedResiduals","page":"Diagnostics","title":"studentizedResiduals","text":"","category":"section"},{"location":"diagnostics/","page":"Diagnostics","title":"Diagnostics","text":"LinRegOutliers.studentizedResiduals","category":"page"},{"location":"diagnostics/#LinRegOutliers.studentizedResiduals","page":"Diagnostics","title":"LinRegOutliers.studentizedResiduals","text":"studentizedResiduals(setting)\n\nCalculate Studentized residuals for a given regression setting.\n\n# Arguments:\n\nsetting::RegressionSetting: A regression setting object.\n\nExamples\n\njulia> reg = createRegressionSetting(@formula(calls ~ year), phones);\n\njulia> studentizedResiduals(reg)\n24-element Array{Float64,1}:\n  0.2398783264505892\n  0.1463945666608097\n  0.04934549995087145\n -0.023289236798461784\n -0.10408303320973748\n -0.18382934382804111\n -0.2609395640240455\n -0.33934473417314376\n -0.3973205657179429\n -0.46258080183149236\n -0.5261488085924144\n -0.5918396227060093\n -0.6616423337899147\n -0.6611792918262785\n  1.0277190922689816\n  1.0297863954540103\n  1.2712201589839855\n  1.4974523565936426\n  1.8386296155264197\n  2.316394853333409\n -0.9368354141338643\n -1.4009989983319822\n -1.4541520919831887\n -1.529459974327181\n\n\n\n\n\n","category":"function"},{"location":"diagnostics/#adjustedResiduals","page":"Diagnostics","title":"adjustedResiduals","text":"","category":"section"},{"location":"diagnostics/","page":"Diagnostics","title":"Diagnostics","text":"LinRegOutliers.adjustedResiduals","category":"page"},{"location":"diagnostics/#LinRegOutliers.adjustedResiduals","page":"Diagnostics","title":"LinRegOutliers.adjustedResiduals","text":"adjustedResiduals(setting)\n\nCalculate adjusted residuals for a given regression setting.\n\n# Arguments:\n\nsetting::RegressionSetting: A regression setting object.\n\nExamples\n\njulia> reg = createRegressionSetting(@formula(calls ~ year), phones);\njulia> adjustedResiduals(reg)\n24-element Array{Float64,1}:\n  13.486773572526268\n   8.2307993473897\n   2.774371467851612\n  -1.3093999279776498\n  -5.851901346871404\n -10.335509559699863\n -14.670907823058053\n -19.07911256736661\n -22.338710565623828\n -26.00786250934617\n -29.58187157605512\n -33.27523207616458\n -37.19977737822219\n -37.173743587631165\n  57.781855070799956\n  57.898085871534626\n  71.47231139524963\n  84.19185329435882\n 103.37399662263209\n 130.23557965295348\n -52.6720662600165\n -78.76891816539992\n -81.75736547266746\n -85.9914301855088\n\n\n\n\n\n","category":"function"},{"location":"diagnostics/#jacknifedS","page":"Diagnostics","title":"jacknifedS","text":"","category":"section"},{"location":"diagnostics/","page":"Diagnostics","title":"Diagnostics","text":"LinRegOutliers.jacknifedS","category":"page"},{"location":"diagnostics/#LinRegOutliers.jacknifedS","page":"Diagnostics","title":"LinRegOutliers.jacknifedS","text":"jacknifedS(setting, k)\n\nEstimate standard error of regression with the kth observation is dropped.\n\n# Arguments\n\nsetting::RegressionSetting: A regression setting object.\nk::Int: Index of the omitted observation. \n\n# Examples\n\njulia> reg = createRegressionSetting(@formula(calls ~ year), phones);\njulia> jacknifedS(reg, 2)\n57.518441664761035\n\njulia> jacknifedS(reg, 15)\n56.14810222161477\n\n\n\n\n\njacknifedS(setting, omittedIndices)\n\nCalculate Jacknife standard error in which the given indices are omitted from the data.\n\nArguments\n\nsetting::RegressionSetting: RegressionSetting object with a formula and dataset.\nomittedIndices::Array{Int, 1}: Indices of omitted variables.\n\nReferences\n\nPeña, Daniel, and Victor J. Yohai. \"The detection of influential subsets in linear  regression by using an influence matrix.\" Journal of the Royal Statistical Society:  Series B (Methodological) 57.1 (1995): 145-156.\n\n\n\n\n\n","category":"function"},{"location":"diagnostics/#cooks","page":"Diagnostics","title":"cooks","text":"","category":"section"},{"location":"diagnostics/","page":"Diagnostics","title":"Diagnostics","text":"LinRegOutliers.cooks","category":"page"},{"location":"diagnostics/#LinRegOutliers.cooks","page":"Diagnostics","title":"LinRegOutliers.cooks","text":"cooks(setting)\n\nCalculate Cook distances for all observations in a regression setting.\n\nArguments\n\nsetting::RegressionSetting: A regression setting object.\n\nExamples\n\njulia> reg = createRegressionSetting(@formula(calls ~ year), phones);\n\njulia> cooks(reg)\n24-element Array{Float64,1}:\n 0.005344774190779822\n 0.0017088194691033689\n 0.00016624914057962608\n 3.1644452583114795e-5\n 0.0005395058666404081\n 0.0014375008774859539\n 0.0024828140956511258\n 0.0036279720445167277\n 0.004357605989540906\n 0.005288503758364767\n 0.006313578057565415\n 0.0076561205696857254\n 0.009568574875389256\n 0.009970039008782357\n 0.02610396373381051\n 0.029272523880917646\n 0.05091236198400663\n 0.08176555044049343\n 0.14380266904640235\n 0.26721539425047447\n 0.051205153558783356\n 0.13401084683481085\n 0.16860324592350226\n 0.2172819114905912\n\nReferences\n\nCook, R. Dennis. \"Detection of influential observation in linear regression.\"  Technometrics 19.1 (1977): 15-18.\n\n\n\n\n\n","category":"function"},{"location":"diagnostics/#mahalanobisSquaredMatrix","page":"Diagnostics","title":"mahalanobisSquaredMatrix","text":"","category":"section"},{"location":"diagnostics/","page":"Diagnostics","title":"Diagnostics","text":"LinRegOutliers.mahalanobisSquaredMatrix","category":"page"},{"location":"diagnostics/#LinRegOutliers.mahalanobisSquaredMatrix","page":"Diagnostics","title":"LinRegOutliers.mahalanobisSquaredMatrix","text":"mahalanobisSquaredMatrix(data::DataFrame; meanvector=nothing, covmatrix=nothing)\n\nCalculate Mahalanobis distances.\n\nArguments\n\ndata::DataFrame: A DataFrame object of the multivariate data.\nmeanvector::Array{Float64, 1}: Optional mean vector of variables.\ncovmatrix::Array{Float64, 2}: Optional covariance matrix of data.\n\n# References Mahalanobis, Prasanta Chandra. \"On the generalized distance in statistics.\"  National Institute of Science of India, 1936.\n\n\n\n\n\n","category":"function"},{"location":"diagnostics/#dfbeta","page":"Diagnostics","title":"dfbeta","text":"","category":"section"},{"location":"diagnostics/","page":"Diagnostics","title":"Diagnostics","text":"LinRegOutliers.dfbeta","category":"page"},{"location":"diagnostics/#LinRegOutliers.dfbeta","page":"Diagnostics","title":"LinRegOutliers.dfbeta","text":"dfbeta(setting, omittedIndex)\n\nApply DFBETA diagnostic for a given regression setting and observation index.\n\nArguments\n\nsetting::RegressionSetting: A regression setting object.\nomittedIndex::Int: Index of the omitted observation.\n\nExample\n\njulia> setting = createRegressionSetting(@formula(calls ~ year), phones);\njulia> dfbeta(setting, 1)\n2-element Array{Float64,1}:\n  9.643915678524024\n -0.14686166007904422\n\n\n\n\n\n","category":"function"},{"location":"diagnostics/#covratio","page":"Diagnostics","title":"covratio","text":"","category":"section"},{"location":"diagnostics/","page":"Diagnostics","title":"Diagnostics","text":"LinRegOutliers.covratio","category":"page"},{"location":"diagnostics/#LinRegOutliers.covratio","page":"Diagnostics","title":"LinRegOutliers.covratio","text":"covratio(setting, omittedIndex)\n\nApply covariance ratio diagnostic for a given regression setting and observation index.\n\nArguments\n\nsetting::RegressionSetting: A regression setting object.\nomittedIndex::Int: Index of the omitted observation.\n\nExample\n\njulia> setting = createRegressionSetting(@formula(calls ~ year), phones);\njulia> covratio(setting, 1)\n1.2945913799871505\n\n\n\n\n\n","category":"function"},{"location":"diagnostics/#hadimeasure","page":"Diagnostics","title":"hadimeasure","text":"","category":"section"},{"location":"diagnostics/","page":"Diagnostics","title":"Diagnostics","text":"LinRegOutliers.hadimeasure","category":"page"},{"location":"diagnostics/#LinRegOutliers.hadimeasure","page":"Diagnostics","title":"LinRegOutliers.hadimeasure","text":"hadimeasure(setting; c = 2.0)\n\nApply Hadi's regression diagnostic for a given regression setting\n\nArguments\n\nsetting::RegressionSetting: A regression setting object.\nc::Float64: Critical value selected between 2.0 - 3.0. The default is 2.0.\n\nExample\n\njulia> setting = createRegressionSetting(@formula(calls ~ year), phones);\njulia> hadimeasure(setting)\n\nReferences\n\nChatterjee, Samprit and Hadi, Ali. Regression Analysis by Example.      5th ed. N.p.: John Wiley & Sons, 2012.\n\n\n\n\n\n","category":"function"},{"location":"#Contents","page":"Contents","title":"Contents","text":"","category":"section"},{"location":"","page":"Contents","title":"Contents","text":"Pages = [\"index.md\", \"datasets.md\", \"types.md\", \"diagnostics.md\", \"algorithms.md\"]\nDepth = 3","category":"page"},{"location":"algorithms/#Algorithms","page":"Algorithms","title":"Algorithms","text":"","category":"section"}]
}
